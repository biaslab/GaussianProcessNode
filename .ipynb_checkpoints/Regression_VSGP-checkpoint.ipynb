{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/PhD/GaussianProcessNode/OldEnvironment`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"OldEnvironment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling IJuliaExt [2f4121a4-3b3a-5ce6-9c5e-1f2673ce168a] (cache misses: wrong dep version loaded (4))\n"
     ]
    }
   ],
   "source": [
    "using ApproximateGPs\n",
    "using Distributions, LinearAlgebra, StatsFuns\n",
    "using PDMats: PDMat\n",
    "using IterTools: ncycle\n",
    "using Flux\n",
    "using Plots\n",
    "using JLD, MAT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMSE (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardized mean squared error (for regression)\n",
    "function SMSE(y_true, y_approx)\n",
    "    N = length(y_true)\n",
    "    mse = norm(y_true - y_approx)^2 / N \n",
    "    return mse / var(y_true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "data_path = \"savefiles/\" \n",
    "xtrain = load(data_path*\"xtrain_toyregression.jld\")[\"xtrain\"]\n",
    "ytrain = load(data_path*\"ytrain_toyregression.jld\")[\"ytrain\"]\n",
    "\n",
    "xtest = load(data_path*\"xtest_toyregression.jld\")[\"xtest\"]\n",
    "ytest = load(data_path*\"ytest_toyregression.jld\")[\"ytest\"]\n",
    "\n",
    "Xu = load(data_path*\"Xu_toyregression.jld\")[\"Xu\"];\n",
    "M = length(Xu);\n",
    "N = length(ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_kernel(k_params)\n",
    "    variance = StatsFuns.softplus(k_params[1])\n",
    "    lengthscale = StatsFuns.softplus(k_params[2])\n",
    "    return variance * with_lengthscale(SqExponentialKernel(), lengthscale)\n",
    "end\n",
    "\n",
    "init_variance = 1\n",
    "init_lengthscale = 1\n",
    "k_init = [StatsFuns.invsoftplus(init_variance), StatsFuns.invsoftplus(init_lengthscale)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SVGPModel\n",
    "    k  # kernel parameters\n",
    "    z  :: AbstractArray# inducing points\n",
    "    m  :: Vector{Float64}# variational mean\n",
    "    A  :: AbstractArray# square-root of variational covariance\n",
    "end\n",
    "\n",
    "Flux.@functor SVGPModel (k, z, m, A);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lik_noise = 0.01\n",
    "jitter = 1e-5;\n",
    "function prior(m::SVGPModel)\n",
    "    kernel = make_kernel(m.k)\n",
    "    return GP(kernel)\n",
    "end\n",
    "function make_approx(m::SVGPModel, prior)\n",
    "    # Efficiently constructs S as A*Aᵀ\n",
    "    S = PDMat(Cholesky(LowerTriangular(m.A)))\n",
    "    q = MvNormal(m.m, S)\n",
    "    fz = prior(m.z, jitter)\n",
    "    return SparseVariationalApproximation(fz, q)\n",
    "end;\n",
    "function model_posterior(m::SVGPModel)\n",
    "    svgp = make_approx(m, prior(m))\n",
    "    return posterior(svgp)\n",
    "end;\n",
    "\n",
    "function (m::SVGPModel)(x)\n",
    "    post = model_posterior(m)\n",
    "    return post(x)\n",
    "end;\n",
    "\n",
    "function loss(m::SVGPModel, x, y; num_data=length(ytrain))\n",
    "    f = prior(m)\n",
    "    fx = f(x, lik_noise)\n",
    "    svgp = make_approx(m, f)\n",
    "    return -elbo(svgp, fx, y; num_data)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_init = zeros(M)\n",
    "A_init = Matrix{Float64}(I, M, M)\n",
    "\n",
    "model = SVGPModel(k_init, Xu, m_init, A_init);\n",
    "opt = AdaMax()  # Define the optimiser\n",
    "params = Flux.params(model);  # Extract the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = Flux.DataLoader((xtrain, ytrain))\n",
    "Flux.train!(\n",
    "    (x, y) -> loss(model, x, y; num_data=N),\n",
    "    Flux.params(model),\n",
    "    ncycle(data_loader, 6000), # Train for 300 epochs\n",
    "    opt,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = model_posterior(model)\n",
    "my_predict = post(xtest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMSE value of VSGP 0.007696940273424477\n"
     ]
    }
   ],
   "source": [
    "println(\"SMSE value of VSGP \", SMSE(ytest, mean(my_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kin40k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_kin40 = matopen(\"data/kin40k/kin40k_xtrain.mat\");\n",
    "xtest_kin40 = matopen(\"data/kin40k/kin40k_xtest.mat\");\n",
    "ytrain_kin40 = matopen(\"data/kin40k/kin40k_ytrain.mat\");\n",
    "ytest_kin40 = matopen(\"data/kin40k/kin40k_ytest.mat\");\n",
    "\n",
    "xtrain_kin40 = read(xtrain_kin40, \"xtrain\") #|> (x) -> Matrix(x');\n",
    "ytrain_kin40 = read(ytrain_kin40, \"ytrain\") |> (x) -> vcat(x...);\n",
    "xtest_kin40 = read(xtest_kin40, \"xtest\") #|> (x) -> Matrix(x');\n",
    "ytest_kin40 = read(ytest_kin40, \"ytest\") |> (x) -> vcat(x...);\n",
    "\n",
    "Ntrain = length(ytrain_kin40);\n",
    "xtrain_kin40 = [xtrain_kin40[i,:] for i=1:Ntrain];\n",
    "data_training = (xtrain_kin40, ytrain_kin40);\n",
    "\n",
    "Ntest = length(ytest_kin40);\n",
    "xtest_kin40 = [xtest_kin40[i,:] for i=1:Ntest];\n",
    "Xu_kin40k = load(data_path*\"Xu_kin40k.jld\")[\"Xu\"] #|> (x) -> hcat(x...);\n",
    "M_kin40k = length(Xu_kin40k);\n",
    "N_kin40k = length(ytrain_kin40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_kernel_kin40k(k_params)\n",
    "    variance = StatsFuns.softplus(k_params[1])\n",
    "    lengthscale = StatsFuns.softplus.(k_params[2:end])\n",
    "    return variance * with_lengthscale(SqExponentialKernel(), lengthscale)\n",
    "end\n",
    "\n",
    "init_variance = 1\n",
    "init_lengthscale = ones(8)\n",
    "k_kin40k_init = [StatsFuns.invsoftplus(init_variance), StatsFuns.invsoftplus.(init_lengthscale)] |> (x) -> vcat(x...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lik_noise = 0.01\n",
    "jitter = 1e-5;\n",
    "function prior_kin40k(m::SVGPModel)\n",
    "    kernel = make_kernel_kin40k(m.k)\n",
    "    return GP(kernel)\n",
    "end\n",
    "function make_approx_kin40k(m::SVGPModel, prior)\n",
    "    # Efficiently constructs S as A*Aᵀ\n",
    "    S = PDMat(Cholesky(LowerTriangular(m.A)))\n",
    "    q = MvNormal(m.m, S)\n",
    "    fz = prior(m.z, jitter)\n",
    "    return SparseVariationalApproximation(fz, q)\n",
    "end;\n",
    "function model_posterior_kin40k(m::SVGPModel)\n",
    "    svgp = make_approx_kin40k(m, prior_kin40k(m))\n",
    "    return posterior(svgp)\n",
    "end;\n",
    "\n",
    "function (m::SVGPModel)(x)\n",
    "    post = model_posterior_kin40k(m)\n",
    "    return post(x)\n",
    "end;\n",
    "\n",
    "function loss(m::SVGPModel, x, y, liknoise; num_data=length(ytrain_kin40))\n",
    "    f = prior_kin40k(m)\n",
    "    fx = f(x, liknoise)\n",
    "    svgp = make_approx_kin40k(m, f)\n",
    "    return -elbo(svgp, fx, y; num_data)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_kin40k_init = zeros(M_kin40k)\n",
    "A_kin40k_init = Matrix{Float64}(I, M_kin40k, M_kin40k)\n",
    "\n",
    "model_kin40k = SVGPModel(k_kin40k_init, Xu_kin40k, m_kin40k_init, A_kin40k_init);\n",
    "opt = AdaMax()  # Define the optimiser\n",
    "params_kin40k = Flux.params(model_kin40k);  # Extract the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 500\n",
    "data_loader = Flux.DataLoader((xtrain_kin40, ytrain_kin40);batchsize=b)\n",
    "@time Flux.train!(\n",
    "    (x, y) -> loss(model_kin40k, x, y,lik_noise; num_data=N_kin40k),\n",
    "    Flux.params(model_kin40k),\n",
    "    ncycle(data_loader, 1), # Train for 4000 epochs\n",
    "    opt,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953027.7330331366"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(model_kin40k,xtrain_kin40,ytrain_kin40,lik_noise;num_data=N_kin40k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = model_posterior_kin40k(model_kin40k)\n",
    "my_predict_kin40k = post(xtest_kin40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMSE value of VSGP 0.9880878565177416\n"
     ]
    }
   ],
   "source": [
    "println(\"SMSE value of VSGP \", SMSE(ytest_kin40, mean(my_predict_kin40k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
