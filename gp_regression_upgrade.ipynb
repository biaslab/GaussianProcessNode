{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `F:\\Tue\\PhD\\GP_playgroundcode`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"F:/Tue/PhD/GP_playgroundcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ReactiveMP, KernelFunctions, Distributions, LinearAlgebra,GraphPPL, Rocket,Plots,Revise \n",
    "using Flux, Zygote, ForwardDiff\n",
    "include(\"utils_gp2.jl\")\n",
    "pgfplotsx()\n",
    "import StatsFuns: log2π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -3, 3  # Bounds of the data\n",
    "N = 200# Number of samples\n",
    "xtrain = sort(rand(Uniform(xmin, xmax), N))\n",
    "xtest = collect(range(xmin - 0.1, xmax + 0.1; length=600));\n",
    "xtest = sort(vcat(xtest,xtrain))\n",
    "precision = 100\n",
    "ytrain = sinc.(xtrain) + randn(N) * sqrt(1/precision);\n",
    "f_true = sinc.(xtest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernelfunc (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# kernelfunc(θ) = with_lengthscale(Matern52Kernel(),θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test new thing\n",
    "@model [ default_factorisation = FullFactorisation() ] function gpprocess(n,kernelfunc,meanfunc,train,test)\n",
    "    y = datavar(Float64,n)\n",
    "    x = randomprocess(test,train)\n",
    "    ### change here \n",
    "    θ = randomvar() where { prod_constraint = ProdGeneric(), marginal_form_constraint = PointMassFormConstraint() }\n",
    "    θ ~ NormalMeanVariance(0.7, 1.)\n",
    "    x ~ GaussianProcess(meanfunc,kernelfunc, θ)\n",
    "    #######\n",
    "    γ ~ GammaShapeRate(1.0,0.1)\n",
    "    for i=1:n \n",
    "        y[i] ~ NormalMeanPrecision(x, γ) where {meta=ProcessMeta(i,nothing,nothing,nothing), q = q(x)q(γ)q(y[i])}\n",
    "    end\n",
    "    return x, γ, θ, y  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Distributions.entropy(pm::PointMass{F}) where {F <: Function}\n",
    "    return ReactiveMP.InfCountingReal(Float64,-1)\n",
    "end\n",
    "\n",
    "function Distributions.entropy(pm::PointMass{F}) where {F <: Kernel}\n",
    "    return ReactiveMP.InfCountingReal(Float64,-1)\n",
    "end\n",
    "\n",
    "###changed \n",
    "@average_energy GaussianProcess (q_out::GaussianProcess, q_meanfunc::Any, q_kernelfunc::Any, q_θ::Any) = begin\n",
    "    q_out.finitemarginal\n",
    "    return -entropy(q_out.finitemarginal)\n",
    "end\n",
    "############\n",
    "\n",
    "@average_energy NormalMeanPrecision (q_out::Any, q_μ::GaussianProcess, q_τ::Any,meta::ProcessMeta) = begin\n",
    "    m_right, cov_right = mean_cov(q_μ.finitemarginal)\n",
    "    kernelf = q_μ.kernelfunction\n",
    "    meanf   = q_μ.meanfunction\n",
    "    test    = q_μ.testinput\n",
    "    train   = q_μ.traininput\n",
    "    μ_mean, μ_var = predMVN(q_μ,test,[train[meta.index]],m_right)\n",
    "    μ_var = clamp(μ_var[1],1e-8,huge)\n",
    "    μ_mean = μ_mean[1]\n",
    "    out_mean, out_var = mean_var(q_out)\n",
    "    return (log2π - mean(log, q_τ) + mean(q_τ) * (μ_var + out_var + abs2(μ_mean - out_mean))) / 2\n",
    "end\n",
    "\n",
    "function ReactiveMP.entropy(p::GaussianProcess)\n",
    "    return ReactiveMP.entropy(p.finitemarginal)\n",
    "end\n",
    "\n",
    "@rule NormalMeanPrecision(:μ, Marginalisation) (q_out::PointMass, q_τ::GammaShapeRate, meta::ProcessMeta) = begin \n",
    "    return @call_rule NormalMeanPrecision(:μ, Marginalisation) (q_out=q_out,q_τ=q_τ,meta=nothing)\n",
    "end\n",
    "# @rule GaussianProcess(:out, Marginalisation) (q_meanfunc::PointMass, q_kernelfunc::PointMass) = begin \n",
    "#     return GaussianProcess(q_meanfunc.point,q_kernelfunc.point,nothing,nothing,nothing,nothing)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_func =  Matern52Kernel() \n",
    "meanfunc   = (x) -> 0.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the product function that computes the product of messages for GP node.\n",
    "# function ReactiveMP.messages_prod_fn(process::RandomProcess)\n",
    "#     test  = process.test_input\n",
    "#     train = process.train_input\n",
    "#     # @show fieldnames(typeof(process))\n",
    "#     return messages -> begin \n",
    "#         m_right,cov_right = make_multivariate_message(map(as_message, messages))\n",
    "\n",
    "#         return Message(MvNormalMeanCovariance(m_right, cov_right), false, false)\n",
    "#     end\n",
    "# end\n",
    "\n",
    "function ReactiveMP.messages_prod_fn(process::RandomProcess)\n",
    "    return ReactiveMP.marginal_prod_fn(process)\n",
    "end\n",
    "\n",
    "function ReactiveMP.marginal_prod_fn(process::RandomProcess)\n",
    "    test  = process.test_input\n",
    "    train = process.train_input\n",
    "\n",
    "    return messages -> begin \n",
    "        message_vector = map(ReactiveMP.as_message, messages)\n",
    "        process_message = getdata(message_vector[1])\n",
    "        meanf = process_message.meanfunction\n",
    "        kernelf = process_message.kernelfunction\n",
    "        likelihood_messages = message_vector[2:end]\n",
    "        m_right,cov_right = make_multivariate_message(likelihood_messages)\n",
    "        \n",
    "        #m, K = predMVN(meta,process_message,train, test, m_right,cov_right)\n",
    "        m, K= predMVN(kernelf,meanf,train,test,m_right,cov_right) #Ismail code\n",
    "        Kff = kernelmatrix(kernelf, test, test)\n",
    "        invKff = cholinv(Kff + K)\n",
    "        return Marginal(GaussianProcess(meanf,kernelf,MvNormalMeanCovariance(m,K),test,train, invKff),false,false)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpconstraints (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraints function gpconstraints()   \n",
    "    q(θ) :: PointMass(starting_point = (args...) -> [ 0.5 ])\n",
    "    q(x,γ) = q(x)q(γ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: Error showing method candidates, aborted\n",
      "│   exception = (UndefRefError(), Union{Ptr{Nothing}, Base.InterpreterIP}[Ptr{Nothing} @0x0000000002733fce, Ptr{Nothing} @0x0000000002700e9c, Ptr{Nothing} @0x0000000000d3b45c, Ptr{Nothing} @0x000000009e6d53ec, Ptr{Nothing} @0x000000009e6d8f20, Ptr{Nothing} @0x000000009e6d9424, Ptr{Nothing} @0x000000009e6c764a, Ptr{Nothing} @0x000000009e6c7813, Ptr{Nothing} @0x000000009e6c7884, Ptr{Nothing} @0x00000000026fd1b6, Ptr{Nothing} @0x000000001c9fa1c3, Ptr{Nothing} @0x000000001c9faace, Ptr{Nothing} @0x000000001c9fad8e, Ptr{Nothing} @0x000000001c9fae04, Ptr{Nothing} @0x000000001c9eeffa, Ptr{Nothing} @0x000000001c9e43c1, Ptr{Nothing} @0x000000001c9e4556, Ptr{Nothing} @0x000000001c9e45c1, Ptr{Nothing} @0x000000001c9deac5, Ptr{Nothing} @0x000000000272a48f, Ptr{Nothing} @0x000000000272ac41, Ptr{Nothing} @0x000000000272bcaf, Ptr{Nothing} @0x0000000010a18f51, Ptr{Nothing} @0x0000000010961205, Ptr{Nothing} @0x000000001031fb58, Ptr{Nothing} @0x00000000107f6f07, Ptr{Nothing} @0x00000000100b6525, Ptr{Nothing} @0x00000000100b66be, Ptr{Nothing} @0x0000000002751b35, Ptr{Nothing} @0x0000000002752555, Ptr{Nothing} @0x0000000000401a63, Ptr{Nothing} @0x00007ffb63397033, Ptr{Nothing} @0x00007ffb64c42650])\n",
      "└ @ Base errorshow.jl:320\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching make_node(::Type{GaussianProcess}, ::FactorNodeCreationOptions{FullFactorisation, Nothing, Nothing}, ::RandomProcess, ::Array{ConstVariable{PointMass{Float64}, SingleObservable{Message{PointMass{Float64}}, AsapScheduler}}, 0}, ::ConstVariable{Matern52Kernel{Distances.Euclidean}, SingleObservable{Message{Matern52Kernel{Distances.Euclidean}}, AsapScheduler}}, ::RandomVariable)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching make_node(::Type{GaussianProcess}, ::FactorNodeCreationOptions{FullFactorisation, Nothing, Nothing}, ::RandomProcess, ::Array{ConstVariable{PointMass{Float64}, SingleObservable{Message{PointMass{Float64}}, AsapScheduler}}, 0}, ::ConstVariable{Matern52Kernel{Distances.Euclidean}, SingleObservable{Message{Matern52Kernel{Distances.Euclidean}}, AsapScheduler}}, ::RandomVariable)\n",
      "\n",
      "Stacktrace:\n",
      " [1] make_node(::FactorGraphModel, ::FactorNodeCreationOptions{Nothing, Nothing, Nothing}, ::Type, ::RandomProcess, ::Array{ConstVariable{PointMass{Float64}, SingleObservable{Message{PointMass{Float64}}, AsapScheduler}}, 0}, ::ConstVariable{Matern52Kernel{Distances.Euclidean}, SingleObservable{Message{Matern52Kernel{Distances.Euclidean}}, AsapScheduler}}, ::RandomVariable)\n",
      "   @ ReactiveMP F:\\Tue\\PhD\\ReactiveMP\\src\\model.jl:490\n",
      " [2] make_node(::FactorGraphModel, ::FactorNodeCreationOptions{Nothing, Nothing, Nothing}, ::Type, ::AutoVar, ::Array{ConstVariable{PointMass{Float64}, SingleObservable{Message{PointMass{Float64}}, AsapScheduler}}, 0}, ::ConstVariable{Matern52Kernel{Distances.Euclidean}, SingleObservable{Message{Matern52Kernel{Distances.Euclidean}}, AsapScheduler}}, ::RandomVariable)\n",
      "   @ ReactiveMP F:\\Tue\\PhD\\ReactiveMP\\src\\model.jl:537\n",
      " [3] macro expansion\n",
      "   @ f:\\Tue\\PhD\\GP_playgroundcode\\gp_regression_upgrade.ipynb:8 [inlined]\n",
      " [4] macro expansion\n",
      "   @ C:\\Users\\LENOVO\\.julia\\packages\\GraphPPL\\5PRXQ\\src\\model.jl:448 [inlined]\n",
      " [5] create_model(::Type{gpprocess}, gpprocessconstraints_in#359::Nothing, gpprocessmeta_in#361::Nothing, gpprocessoptions_in#363::ModelOptions{Nothing, Nothing, ReactiveMP.LimitStackScheduler}, n::Int64, kernelfunc::Matern52Kernel{Distances.Euclidean}, meanfunc::Function, train::Vector{Float64}, test::Vector{Float64})\n",
      "   @ Main C:\\Users\\LENOVO\\.julia\\packages\\GraphPPL\\5PRXQ\\src\\backends\\reactivemp.jl:73\n",
      " [6] create_model(generator::ReactiveMP.ModelGenerator{gpprocess, Tuple{Int64, Matern52Kernel{Distances.Euclidean}, var\"#93#94\", Vector{Float64}, Vector{Float64}}, Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}, Nothing, Nothing, Nothing}, constraints::Nothing, meta::Nothing, options::ModelOptions{Nothing, Nothing, ReactiveMP.LimitStackScheduler})\n",
      "   @ ReactiveMP F:\\Tue\\PhD\\ReactiveMP\\src\\model.jl:48\n",
      " [7] inference(; model::ReactiveMP.ModelGenerator{gpprocess, Tuple{Int64, Matern52Kernel{Distances.Euclidean}, var\"#93#94\", Vector{Float64}, Vector{Float64}}, Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}, Nothing, Nothing, Nothing}, data::NamedTuple{(:y,), Tuple{Vector{Float64}}}, initmarginals::NamedTuple{(:γ,), Tuple{GammaShapeRate{Float64}}}, initmessages::Nothing, constraints::Nothing, meta::Nothing, options::ModelOptions{Nothing, Nothing, ReactiveMP.LimitStackScheduler}, returnvars::Nothing, iterations::Int64, free_energy::Bool, free_energy_diagnostics::Tuple{BetheFreeEnergyCheckNaNs, BetheFreeEnergyCheckInfs}, showprogress::Bool, callbacks::Nothing, warn::Bool)\n",
      "   @ ReactiveMP F:\\Tue\\PhD\\ReactiveMP\\src\\inference.jl:338\n",
      " [8] top-level scope\n",
      "   @ f:\\Tue\\PhD\\GP_playgroundcode\\gp_regression_upgrade.ipynb:2"
     ]
    }
   ],
   "source": [
    "nits = 1\n",
    "iresult = inference(\n",
    "    model = Model(gpprocess, length(ytrain), kernel_func, meanfunc, xtrain,xtest),\n",
    "    initmarginals = (γ = vague(GammaShapeRate),),\n",
    "    options = model_options(limit_stack_depth = 500),\n",
    "    # constraints = gpconstraints(),\n",
    "    iterations = nits,  \n",
    "    data  = (y = ytrain,),\n",
    "    showprogress=true,\n",
    "    free_energy = true\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
